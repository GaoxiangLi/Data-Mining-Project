{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_dis: 1066.4858585571126\n",
      "DVI: 0.44443934881793357\n",
      "DB: 1.0420064256703199\n",
      "running time: 20.169259071350098\n",
      "sum_dis: 1067.1392527118603\n",
      "DVI: 0.40708356490627096\n",
      "DB: 1.052046273457634\n",
      "running time: 16.135871410369873\n",
      "sum_dis: 1067.0845443202388\n",
      "DVI: 0.3836017397542227\n",
      "DB: 1.0712905651617621\n",
      "running time: 15.412123680114746\n",
      "sum_dis: 1062.3703591825376\n",
      "DVI: 0.424124011553921\n",
      "DB: 1.0606858556761067\n",
      "running time: 15.817102909088135\n",
      "sum_dis: 1067.841889917625\n",
      "DVI: 0.41950322697582293\n",
      "DB: 1.0896950562791208\n",
      "running time: 21.38218379020691\n",
      "sum_dis: 1071.1660745472461\n",
      "DVI: 0.44809042839807267\n",
      "DB: 1.0507299038678266\n",
      "running time: 13.212323427200317\n",
      "sum_dis: 1075.1520219701788\n",
      "DVI: 0.42730541290138924\n",
      "DB: 1.0787851084859397\n",
      "running time: 18.113230228424072\n",
      "sum_dis: 1050.715437296431\n",
      "DVI: 0.41797192070033473\n",
      "DB: 1.0363192618892918\n",
      "running time: 14.941414594650269\n",
      "sum_dis: 1056.6064238121076\n",
      "DVI: 0.3860487219032932\n",
      "DB: 1.0477922098566492\n",
      "running time: 15.020453929901123\n",
      "sum_dis: 1108.524939189231\n",
      "DVI: 0.3048454013511961\n",
      "DB: 1.1109540010938594\n",
      "running time: 19.144862174987793\n",
      "everage distance: 1069.3086801504567\n",
      "everage time: 16.934882521629333\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random, randint,sample,uniform\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from scipy import spatial\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "def initialize_data(filename):\n",
    "    #readData\n",
    "    train_data = pd.read_csv(filename)\n",
    "    \n",
    "    #normalize the datasets\n",
    "    train_nor = (train_data -train_data.mean())/train_data.std()\n",
    "    \n",
    "    #convert dataFrame into dataList and show\n",
    "    train_nor[\"Group\"] = 0\n",
    "    dataList = train_nor.values.tolist()\n",
    "    return dataList\n",
    "    \n",
    "def generate_centroid(k,dataList):\n",
    "        clusters = list()\n",
    "        First = deepcopy(dataList[randint(0,len(dataList)-1)])[0:-1]\n",
    "        clusters.append(First)\n",
    "        while(len(clusters) != k):\n",
    "            sum_distance = 0\n",
    "            disList = list()\n",
    "            for j in dataList:\n",
    "                mins = 100000\n",
    "                dis = 0\n",
    "                for i in range(len(clusters)):\n",
    "                    dis = calculate(j,clusters[i])\n",
    "                    if dis < mins:\n",
    "                        mins = dis\n",
    "                sum_distance = sum_distance + mins**(2)\n",
    "                disList.append(mins**(2))\n",
    "            tem = uniform(0,sum_distance) \n",
    "            time = 0 \n",
    "            while(tem>0):\n",
    "                tem = tem - disList[time]\n",
    "                time = time + 1\n",
    "            clusters.append(deepcopy(dataList[time-1])[0:-1])\n",
    "        return clusters\n",
    "\n",
    "def kmeans_generate_centroid(k,dataList):\n",
    "    clusters = list()\n",
    "    for i in range(k):\n",
    "        First = deepcopy(dataList[randint(0,len(dataList)-1)])[0:-1]\n",
    "        clusters.append(First)\n",
    "    return clusters\n",
    "    \n",
    "def calculate(record_1,record_2):\n",
    "    distance = 0\n",
    "    for x in range(10):\n",
    "        distance += (record_1[x]-record_2[x])**(2)\n",
    "    return distance**(0.5)\n",
    "\n",
    "def update_group(dataList,clusters):\n",
    "    while True:\n",
    "        changed = 0;\n",
    "        for p in dataList:\n",
    "            mins = 10000000\n",
    "            ori_group = p[-1]\n",
    "            for i in range(len(clusters)):\n",
    "                dis = calculate(p,clusters[i])\n",
    "                if (dis < mins):\n",
    "                   mins = dis\n",
    "                   p[-1] = i+1\n",
    "            if(ori_group != p[-1]):\n",
    "                changed = changed + 1\n",
    "        update_centroid(dataList,clusters)\n",
    "        if(changed == 0):\n",
    "                break;\n",
    "def update_centroid(dataList,clusters):\n",
    "    for i in range(len(clusters)):\n",
    "        sum_list = [0 for i in range(len(clusters[i]))]\n",
    "        num = 0\n",
    "        for j in dataList:\n",
    "            if(j[-1] == (i+1)):\n",
    "                num = num + 1\n",
    "                for k in range(len(j)-1):\n",
    "                    sum_list[k] = sum_list[k] + j[k]\n",
    "        #print(\"cluster:\",(i+1),num)\n",
    "        for n in range(len(clusters[0])):\n",
    "            if num > 0:\n",
    "                clusters[i][n] = sum_list[n]/num\n",
    "    \n",
    "def calculate_sumDistance(dataList,clusters):\n",
    "    sum_dis = 0\n",
    "    for i in dataList:\n",
    "        group = i[-1]-1\n",
    "        dis = calculate(i,clusters[group])\n",
    "        sum_dis += dis\n",
    "        \n",
    "    return sum_dis\n",
    "   \n",
    "def kmeansPlus(filename,k):\n",
    "    dataList = initialize_data(filename)\n",
    "    clusters = generate_centroid(k,dataList)\n",
    "    update_group(dataList,clusters)\n",
    "    dis = calculate_sumDistance(dataList,clusters)\n",
    "    DVI = DuneIndex(dataList,clusters)\n",
    "    DB = BouldinIndex(dataList,clusters)\n",
    "    df = pd.DataFrame(dataList)\n",
    "    print(\"sum_dis:\",dis)\n",
    "    print(\"DVI:\",DVI)\n",
    "    print(\"DB:\",DB)\n",
    "    return dis\n",
    "\n",
    "def kmeans(filename,k):\n",
    "    dataList = initialize_data(filename)\n",
    "    clusters = kmeans_generate_centroid(k,dataList)\n",
    "    update_group(dataList,clusters)\n",
    "    dis = calculate_sumDistance(dataList,clusters)\n",
    "    DVI = DuneIndex(dataList,clusters)\n",
    "    DB = BouldinIndex(dataList,clusters)\n",
    "    df = pd.DataFrame(dataList)\n",
    "    print(\"sum_dis:\",dis)\n",
    "    print(\"DVI:\",DVI)\n",
    "    print(\"DB:\",DB)\n",
    "    return dis\n",
    "\n",
    "#measures to evaluate\n",
    "#DuneIndex\n",
    "def DuneIndex(dataList,clusters):\n",
    "    minintro_dis = 10000000\n",
    "    maxinner_dis = 0\n",
    "    for j in clusters:\n",
    "        for k in clusters:\n",
    "            if(j != k):\n",
    "                dis = calculate(j,k)\n",
    "                if (dis <minintro_dis):\n",
    "                    minintro_dis = dis\n",
    "    for m in dataList:\n",
    "        for n in dataList:\n",
    "            if (m[-1] == n[-1]):\n",
    "                dis = calculate(m,n)\n",
    "                if (dis > maxinner_dis):\n",
    "                    maxinner_dis = dis\n",
    "    DVI = minintro_dis**(0.5) / maxinner_dis**(0.5)\n",
    "    return DVI\n",
    "\n",
    "def calculate_averageDis(dataList,cluster,index):\n",
    "    sum_dis = 0\n",
    "    count = 0\n",
    "    for i in dataList:\n",
    "        if(i[-1] == index):\n",
    "            dis = calculate(i,cluster)\n",
    "            sum_dis = sum_dis + dis\n",
    "            count = count + 1\n",
    "    ave = sum_dis/count\n",
    "    return ave\n",
    "\n",
    "#Davis Index\n",
    "def BouldinIndex(dataList,clusters):\n",
    "    sum_dis = 0\n",
    "    for i in range(len(clusters)):\n",
    "        max_dis = 0\n",
    "        for j in range(len(clusters)):\n",
    "            if (i != j):\n",
    "                dis_1 = calculate_averageDis(dataList,clusters[i],i+1) + calculate_averageDis(dataList,clusters[j],j+1)\n",
    "                dis_2 = calculate(clusters[i],clusters[j])\n",
    "                result = dis_1 / dis_2\n",
    "                if (result > max_dis):\n",
    "                    max_dis = result\n",
    "        sum_dis = sum_dis + max_dis\n",
    "    DB = sum_dis / len(clusters)\n",
    "    return DB\n",
    "    \n",
    "final = 0\n",
    "min_dis = 10000\n",
    "total_time = 0\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    #dis = kmeansPlus(\"cloudData.csv\",50)\n",
    "    dis2 = kmeans(\"cloudData.csv\",50)\n",
    "    run_time = time.time()-start_time\n",
    "    print(\"running time:\",run_time)\n",
    "    final += dis2\n",
    "    total_time = total_time + run_time\n",
    "average = final / 10\n",
    "print(\"everage distance:\",average)\n",
    "print(\"everage time:\",total_time/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "sum_list = [0 for i in range(10)]\n",
    "print(sum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
